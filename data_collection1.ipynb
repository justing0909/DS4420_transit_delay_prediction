{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS4420 Transit Data EDA\n",
    "Exploring GTFS Schedule data for the MBTA. Loading data, observing features and preparing for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum alert date: 2021-05-25 17:08:09-04:00\n",
      "Maximum alert date: 2025-04-12 10:45:29-04:00\n"
     ]
    }
   ],
   "source": [
    "# MBTA API endpoint for alerts\n",
    "url = \"https://api-v3.mbta.com/alerts\"\n",
    "\n",
    "# Parameters to get alerts\n",
    "params = {\n",
    "    \"api_key\": \"f8a9ad97579d4ed2978147f7187eced5\",  # Replace with your API key\n",
    "    \"page[limit]\": 700  # Adjust as needed\n",
    "}\n",
    "\n",
    "# Fetch alerts data\n",
    "response = requests.get(url, params=params)\n",
    "alerts_data = response.json()\n",
    "\n",
    "# Extract 'created_at' dates from the alerts\n",
    "dates = []\n",
    "for alert in alerts_data.get('data', []):\n",
    "    created_at = alert.get('attributes', {}).get('created_at')\n",
    "    if created_at:\n",
    "        dt = datetime.fromisoformat(created_at.replace('Z', '+00:00'))\n",
    "        dates.append(dt)\n",
    "\n",
    "# Compute min and max dates if available\n",
    "if dates:\n",
    "    min_date = min(dates)\n",
    "    max_date = max(dates)\n",
    "    print(\"Minimum alert date:\", min_date)\n",
    "    print(\"Maximum alert date:\", max_date)\n",
    "else:\n",
    "    print(\"No alert dates found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predicted data for T by stop id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arrival_time': '2025-04-12T10:58:02-04:00', 'departure_time': '2025-04-12T10:58:56-04:00', 'departure_uncertainty': 60, 'direction_id': 0, 'status': None, 'stop_sequence': 140, 'schedule_relationship': None}\n",
      "{'arrival_time': '2025-04-12T11:06:14-04:00', 'departure_time': '2025-04-12T11:07:08-04:00', 'departure_uncertainty': 60, 'direction_id': 0, 'status': None, 'stop_sequence': 140, 'schedule_relationship': None}\n",
      "{'arrival_time': '2025-04-12T11:12:58-04:00', 'departure_time': '2025-04-12T11:13:52-04:00', 'departure_uncertainty': 60, 'direction_id': 0, 'status': None, 'stop_sequence': 140, 'schedule_relationship': None}\n",
      "{'arrival_time': '2025-04-12T11:20:01-04:00', 'departure_time': '2025-04-12T11:20:55-04:00', 'departure_uncertainty': 120, 'direction_id': 0, 'status': None, 'stop_sequence': 140, 'schedule_relationship': None}\n",
      "{'arrival_time': '2025-04-12T11:27:59-04:00', 'departure_time': '2025-04-12T11:28:53-04:00', 'departure_uncertainty': 120, 'direction_id': 0, 'status': None, 'stop_sequence': 140, 'schedule_relationship': None}\n",
      "{'arrival_time': '2025-04-12T11:37:01-04:00', 'departure_time': '2025-04-12T11:37:55-04:00', 'departure_uncertainty': 360, 'direction_id': 0, 'status': None, 'stop_sequence': 140, 'schedule_relationship': None}\n",
      "{'arrival_time': '2025-04-12T11:45:01-04:00', 'departure_time': '2025-04-12T11:45:55-04:00', 'departure_uncertainty': 360, 'direction_id': 0, 'status': None, 'stop_sequence': 140, 'schedule_relationship': None}\n",
      "{'arrival_time': '2025-04-12T11:53:01-04:00', 'departure_time': '2025-04-12T11:53:55-04:00', 'departure_uncertainty': 360, 'direction_id': 0, 'status': None, 'stop_sequence': 140, 'schedule_relationship': None}\n",
      "{'arrival_time': '2025-04-12T12:01:01-04:00', 'departure_time': '2025-04-12T12:01:55-04:00', 'departure_uncertainty': 360, 'direction_id': 0, 'status': None, 'stop_sequence': 140, 'schedule_relationship': None}\n",
      "{'arrival_time': '2025-04-12T12:09:01-04:00', 'departure_time': '2025-04-12T12:09:55-04:00', 'departure_uncertainty': 360, 'direction_id': 0, 'status': None, 'stop_sequence': 140, 'schedule_relationship': None}\n"
     ]
    }
   ],
   "source": [
    "# MBTA API endpoint for alerts\n",
    "url = \"https://api-v3.mbta.com/predictions?filter[stop]=70010\" # predictions for stop 70010, e.g., Orange Line Ruggles in the direction of Forest Hills\n",
    "\n",
    "# Parameters to get alerts\n",
    "params = {\n",
    "    \"api_key\": \"f8a9ad97579d4ed2978147f7187eced5\",  # Replace with your API key\n",
    "    \"page[limit]\": 700  # Adjust as needed\n",
    "}\n",
    "\n",
    "# Fetch predictions data\n",
    "response = requests.get(url, params=params)\n",
    "predictions_data = response.json()\n",
    "\n",
    "# Extract relevant information from the predictions\n",
    "predictions = []\n",
    "for prediction in predictions_data.get('data', []):\n",
    "    attributes = prediction.get('attributes', {})\n",
    "    predictions.append({\n",
    "        'arrival_time': attributes.get('arrival_time'),\n",
    "        'departure_time': attributes.get('departure_time'),\n",
    "        'departure_uncertainty': attributes.get('departure_uncertainty'),\n",
    "        'direction_id': attributes.get('direction_id'),\n",
    "        'status': attributes.get('status'),\n",
    "        'stop_sequence': attributes.get('stop_sequence'),\n",
    "        'schedule_relationship': attributes.get('schedule_relationship')\n",
    "    })\n",
    "\n",
    "# Display the predictions\n",
    "if predictions:\n",
    "    for pred in predictions:\n",
    "        print(pred)\n",
    "else:\n",
    "    print(\"No predictions found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scheduled Data for T by stop id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://api-v3.mbta.com//schedules?filter[stop]=70010\" # actual schedule for stop 70010, e.g., Orange Line Ruggles in the direction of Forest Hills\n",
    "\n",
    "# Parameters to get alerts\n",
    "params = {\n",
    "    \"api_key\": \"f8a9ad97579d4ed2978147f7187eced5\",  # Replace with your API key\n",
    "    \"page[limit]\": 700  # Adjust as needed\n",
    "}\n",
    "# Fetch predictions data\n",
    "response = requests.get(url, params=params)\n",
    "schedules_data = response.json()\n",
    "# Extract relevant information from the predictions\n",
    "schedules = []\n",
    "for schedule in schedules_data.get('data', []):\n",
    "    attributes = schedule.get('attributes', {})\n",
    "    schedules.append({\n",
    "        'arrival_time': attributes.get('arrival_time'),\n",
    "        'departure_time': attributes.get('departure_time'),\n",
    "        'departure_uncertainty': attributes.get('departure_uncertainty'),\n",
    "        'direction_id': attributes.get('direction_id'),\n",
    "        'status': attributes.get('status'),\n",
    "        'stop_sequence': attributes.get('stop_sequence'),\n",
    "        'schedule_relationship': attributes.get('schedule_relationship')\n",
    "    })\n",
    "# Display the predictions\n",
    "if schedules:\n",
    "    for schedule in schedules:\n",
    "        print(schedule)\n",
    "else:\n",
    "    print(\"No schedules found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculating expected arrival delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching schedule index: 38\n",
      "Matching schedule: {'arrival_time': '2025-04-12T10:56:00-04:00', 'departure_time': '2025-04-12T10:56:00-04:00', 'departure_uncertainty': None, 'direction_id': 0, 'status': None, 'stop_sequence': 140, 'schedule_relationship': None}\n",
      "Associated prediction: {'arrival_time': '2025-04-12T10:58:02-04:00', 'departure_time': '2025-04-12T10:58:56-04:00', 'departure_uncertainty': 60, 'direction_id': 0, 'status': None, 'stop_sequence': 140, 'schedule_relationship': None}\n"
     ]
    }
   ],
   "source": [
    "# index into schedules where the arrival time contains the same time as the first prediction with an error of +/- 3 minutes (when MBTA considers a train is \"on time\")\n",
    "def find_matching_schedule(predictions, schedules):\n",
    "    for i, pred in enumerate(predictions):\n",
    "        arrival_time = pred['arrival_time']\n",
    "        arrival_time_dt = datetime.fromisoformat(arrival_time.replace('Z', '+00:00'))\n",
    "        # Check if the arrival time is within +/- 3 minutes of any schedule\n",
    "        for j, schedule in enumerate(schedules):\n",
    "            schedule_arrival_time = schedule['arrival_time']\n",
    "            schedule_arrival_time_dt = datetime.fromisoformat(schedule_arrival_time.replace('Z', '+00:00'))\n",
    "            if abs((arrival_time_dt - schedule_arrival_time_dt).total_seconds()) <= 180:\n",
    "                return i, j  # Return the indices of the matching prediction and schedule\n",
    "    return None, None  # Return None if no match is found\n",
    "# Find the indices of the matching prediction and schedule\n",
    "# Ensure predictions and schedules are not empty\n",
    "if predictions and schedules:\n",
    "    matching_pred_index, matching_sched_index = find_matching_schedule(predictions, schedules)\n",
    "    if matching_sched_index is not None:\n",
    "        print(f\"Matching schedule index: {matching_sched_index}\")\n",
    "        print(f\"Matching schedule: {schedules[matching_sched_index]}\")\n",
    "        print(f\"Associated prediction: {predictions[matching_pred_index]}\")\n",
    "    else:\n",
    "        print(\"No matching schedule found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference array of scheduled arrival times with tolerance (in seconds):\n",
      "[['2025-04-12T10:56:00-04:00' '-122.0']\n",
      " ['2025-04-12T11:04:00-04:00' '-134.0']\n",
      " ['2025-04-12T11:12:00-04:00' '-58.0']\n",
      " ['2025-04-12T11:20:00-04:00' '-1.0']\n",
      " ['2025-04-12T11:28:00-04:00' '1.0']\n",
      " ['2025-04-12T11:37:00-04:00' '-1.0']\n",
      " ['2025-04-12T11:45:00-04:00' '-1.0']\n",
      " ['2025-04-12T11:53:00-04:00' '-1.0']\n",
      " ['2025-04-12T12:01:00-04:00' '-1.0']\n",
      " ['2025-04-12T12:09:00-04:00' '-1.0']]\n"
     ]
    }
   ],
   "source": [
    "# now, calculate the difference between the predicted arrival time and the actual arrival time\n",
    "def calculate_time_difference_within_tolerance(predictions, schedules):\n",
    "    time_differences = []\n",
    "    for pred in predictions:\n",
    "        arrival_time = pred['arrival_time']\n",
    "        arrival_time_dt = datetime.fromisoformat(arrival_time.replace('Z', '+00:00'))\n",
    "        for schedule in schedules:\n",
    "            schedule_arrival_time = schedule['arrival_time']\n",
    "            schedule_arrival_time_dt = datetime.fromisoformat(schedule_arrival_time.replace('Z', '+00:00'))\n",
    "            # Check if the times are within +/- 3 minutes\n",
    "            if abs((arrival_time_dt - schedule_arrival_time_dt).total_seconds()) <= 180:\n",
    "                time_difference = (schedule_arrival_time_dt - arrival_time_dt).total_seconds() / 60  # Convert to minutes\n",
    "                time_differences.append((schedule_arrival_time, arrival_time, time_difference))\n",
    "                break  # Stop checking once a match is found\n",
    "    return time_differences\n",
    "\n",
    "# Calculate the time differences\n",
    "if predictions and schedules:\n",
    "    time_differences_within_tolerance = calculate_time_difference_within_tolerance(predictions, schedules)\n",
    "    # print(\"Time differences within tolerance (in minutes):\")\n",
    "    # print(time_differences_within_tolerance)\n",
    "\n",
    "# store this value in a numpy array with the associated scheduled arrival time and predicted arrival time\n",
    "def create_time_difference_array_within_tolerance(predictions, schedules):\n",
    "    time_diff_array = []\n",
    "    for pred in predictions:\n",
    "        arrival_time = pred['arrival_time']\n",
    "        arrival_time_dt = datetime.fromisoformat(arrival_time.replace('Z', '+00:00'))\n",
    "        for schedule in schedules:\n",
    "            schedule_arrival_time = schedule['arrival_time']\n",
    "            schedule_arrival_time_dt = datetime.fromisoformat(schedule_arrival_time.replace('Z', '+00:00'))\n",
    "            # Check if the times are within +/- 3 minutes\n",
    "            if abs((arrival_time_dt - schedule_arrival_time_dt).total_seconds()) <= 180:\n",
    "                time_difference = (schedule_arrival_time_dt - arrival_time_dt).total_seconds()\n",
    "                time_diff_array.append([schedule_arrival_time, time_difference])\n",
    "                break  # Stop checking once a match is found\n",
    "    return np.array(time_diff_array)\n",
    "\n",
    "# Create the time difference array\n",
    "if predictions and schedules:\n",
    "    time_diff_array_within_tolerance = create_time_difference_array_within_tolerance(predictions, schedules)\n",
    "    print(\"Time difference array of scheduled arrival times with tolerance (in seconds):\")\n",
    "    print(time_diff_array_within_tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check, make suere there are no other arrival times in the schedule witihin +/- 3 minutes of the associated prediction\n",
    "def find_other_matching_schedules(predictions, schedules, matching_sched_index):\n",
    "    for i, schedule in enumerate(schedules):\n",
    "        if i == matching_sched_index:\n",
    "            continue  # Skip the matching schedule\n",
    "        schedule_arrival_time = schedule['arrival_time']\n",
    "        schedule_arrival_time_dt = datetime.fromisoformat(schedule_arrival_time.replace('Z', '+00:00'))\n",
    "        # Check if the arrival time is within +/- 3 minutes of the associated prediction\n",
    "        for j, pred in enumerate(predictions):\n",
    "            arrival_time = pred['arrival_time']\n",
    "            arrival_time_dt = datetime.fromisoformat(arrival_time.replace('Z', '+00:00'))\n",
    "            if abs((arrival_time_dt - schedule_arrival_time_dt).total_seconds()) <= 180:\n",
    "                return i  # Return the index of the other matching schedule\n",
    "    return None  # Return None if no other match is found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api.open-meteo.com/v1/forecast?latitude=42.3584&longitude=-71.0598&hourly=temperature_2m,precipitation,rain,showers,snowfall,snow_depth&minutely_15=temperature_2m,snowfall,precipitation,rain&past_days=14&forecast_days=16&wind_speed_unit=mph&temperature_unit=fahrenheit&precipitation_unit=inch\"\n",
    "# Fetch weather data\n",
    "response = requests.get(url)\n",
    "weather_data = response.json()\n",
    "\n",
    "\n",
    "# Restructure the weather data\n",
    "weather = []\n",
    "for i, time in enumerate(weather_data['minutely_15']['time']):\n",
    "    weather.append({\n",
    "        'time': time,\n",
    "        'temperature_2m': weather_data['minutely_15']['temperature_2m'][i],\n",
    "        'precipitation': weather_data['minutely_15']['precipitation'][i],\n",
    "    })\n",
    "\n",
    "# change dictionaries to rows\n",
    "weather_array = np.array([list(d.values()) for d in weather])\n",
    "\n",
    "# add bias\n",
    "weather_array = np.insert(weather_array, 0, 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1', '2025-03-29T00:00', '54.1', '0.0'],\n",
       "       ['1', '2025-03-29T00:15', '53.6', '0.0'],\n",
       "       ['1', '2025-03-29T00:30', '52.4', '0.0'],\n",
       "       ...,\n",
       "       ['1', '2025-04-27T23:15', '68.8', '0.0'],\n",
       "       ['1', '2025-04-27T23:30', '68.0', '0.0'],\n",
       "       ['1', '2025-04-27T23:45', '67.3', '0.0']], dtype='<U32')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['2025-04-12T10:56:00-04:00' '-122.0']\n",
      " ['2025-04-12T11:04:00-04:00' '-134.0']\n",
      " ['2025-04-12T11:12:00-04:00' '-58.0']\n",
      " ['2025-04-12T11:20:00-04:00' '-1.0']\n",
      " ['2025-04-12T11:28:00-04:00' '1.0']\n",
      " ['2025-04-12T11:37:00-04:00' '-1.0']\n",
      " ['2025-04-12T11:45:00-04:00' '-1.0']\n",
      " ['2025-04-12T11:53:00-04:00' '-1.0']\n",
      " ['2025-04-12T12:01:00-04:00' '-1.0']\n",
      " ['2025-04-12T12:09:00-04:00' '-1.0']]\n",
      "train delay shape: (10, 2)\n"
     ]
    }
   ],
   "source": [
    "print(time_diff_array_within_tolerance)\n",
    "print(f\"train delay shape: {time_diff_array_within_tolerance.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1' '2025-03-29T00:00' '54.1' '0.0']\n",
      " ['1' '2025-03-29T00:15' '53.6' '0.0']\n",
      " ['1' '2025-03-29T00:30' '52.4' '0.0']\n",
      " ...\n",
      " ['1' '2025-04-27T23:15' '68.8' '0.0']\n",
      " ['1' '2025-04-27T23:30' '68.0' '0.0']\n",
      " ['1' '2025-04-27T23:45' '67.3' '0.0']]\n",
      "Weather data shape: (2880, 4)\n"
     ]
    }
   ],
   "source": [
    "print(weather_array)\n",
    "print(f\"Weather data shape: {weather_array.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched weather array:\n",
      "[['1' '0.024' '34.3' '-122.0']\n",
      " ['1' '0.0' '34.2' '-122.0']\n",
      " ['1' '0.02' '33.8' '-134.0']\n",
      " ['1' '0.016' '33.9' '-1.0']\n",
      " ['1' '0.008' '34.0' '-1.0']\n",
      " ['1' '0.0' '34.3' '-1.0']\n",
      " ['1' '0.004' '34.0' '-1.0']]\n"
     ]
    }
   ],
   "source": [
    "# match the index of the weather array to the index of the time difference array by comparing the time of the weather array to the time of the time difference array.\n",
    "# if the arrival time is within 15 minutes past the weather time, then that arrival time gets that weather data associated with it\n",
    "def match_weather_to_time_diff(weather_array, time_diff_array_within_tolerance):\n",
    "    matched_data = []\n",
    "    for i, weather in enumerate(weather_array):\n",
    "        weather_time = datetime.fromisoformat(weather[1].replace('Z', '+00:00')).astimezone(None)\n",
    "        for j, time_diff in enumerate(time_diff_array_within_tolerance):\n",
    "            schedule_arrival_time = datetime.fromisoformat(time_diff[0].replace('Z', '+00:00')).astimezone(None)\n",
    "            # Calculate actual time by adding delay to scheduled time\n",
    "            delay_seconds = float(time_diff[1])\n",
    "            actual_arrival_time = schedule_arrival_time + timedelta(seconds=abs(delay_seconds))\n",
    "            \n",
    "            if abs((schedule_arrival_time - weather_time).total_seconds()) <= 900:\n",
    "                matched_data.append({\n",
    "                    'bias': weather[0],                   # Bias from weather data\n",
    "                    'precip': weather[3],                 # Precipitation from weather data\n",
    "                    'temp': weather[2],                   # Temperature from weather data\n",
    "                    'delay': time_diff[1],                # Time difference (delay)\n",
    "                    'scheduled_time': time_diff[0],       # Scheduled arrival time\n",
    "                    'actual_time': actual_arrival_time.isoformat()  # Calculated actual arrival time\n",
    "                })\n",
    "                break  # Stop checking once a match is found\n",
    "    return matched_data\n",
    "\n",
    "# Match the weather data to the time difference array\n",
    "if time_diff_array_within_tolerance.size > 0 and weather_array.size > 0:\n",
    "    matched_weather_data = match_weather_to_time_diff(weather_array, time_diff_array_within_tolerance)\n",
    "    # print(\"Matched weather data:\")\n",
    "    for data in matched_weather_data:\n",
    "        # print(data)\n",
    "        pass\n",
    "else:\n",
    "    print(\"No matched weather data found.\")\n",
    "\n",
    "# create a numpy array from the data\n",
    "def create_matched_weather_array(matched_weather_data):\n",
    "    matched_weather_array = []\n",
    "    for data in matched_weather_data:\n",
    "        matched_weather_array.append([\n",
    "            data['bias'],           # Bias\n",
    "            data['precip'],         # Precipitation\n",
    "            data['temp'],           # Temperature\n",
    "            data['delay'],          # Delay (time difference)\n",
    "        ])\n",
    "    return np.array(matched_weather_array)\n",
    "\n",
    "# Create the matched weather array\n",
    "if matched_weather_data:\n",
    "    matched_weather_array = create_matched_weather_array(matched_weather_data)\n",
    "    print(\"Matched weather array:\")\n",
    "    print(matched_weather_array)\n",
    "else:\n",
    "    print(\"No matched weather data found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['2025-04-12T10:56:00-04:00', '1', '2025-04-12T10:45', '34.3',\n",
       "        '0.024'],\n",
       "       ['2025-04-12T10:56:00-04:00', '1', '2025-04-12T11:00', '34.2',\n",
       "        '0.0'],\n",
       "       ['2025-04-12T11:04:00-04:00', '1', '2025-04-12T11:15', '33.8',\n",
       "        '0.02'],\n",
       "       ['2025-04-12T11:20:00-04:00', '1', '2025-04-12T11:30', '33.9',\n",
       "        '0.016'],\n",
       "       ['2025-04-12T11:37:00-04:00', '1', '2025-04-12T11:45', '34.0',\n",
       "        '0.008'],\n",
       "       ['2025-04-12T11:45:00-04:00', '1', '2025-04-12T12:00', '34.3',\n",
       "        '0.0'],\n",
       "       ['2025-04-12T12:01:00-04:00', '1', '2025-04-12T12:15', '34.0',\n",
       "        '0.004']], dtype='<U25')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_weather_array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
